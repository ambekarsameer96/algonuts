{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet for AlgoNuts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3bb8a48346fa4180a583b255351f4783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_881b4581a5514b98991a47a66337f26a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_525b00faca7e4a4891d9743b41dba189",
              "IPY_MODEL_da029b3776ec4cd7b0cac2a303236ce6"
            ]
          }
        },
        "881b4581a5514b98991a47a66337f26a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "525b00faca7e4a4891d9743b41dba189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed556bd2978e465f8fbe98c565998f92",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a2a232c8cfe47fd95cb05fb814e7906"
          }
        },
        "da029b3776ec4cd7b0cac2a303236ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_560947e49c664a7b9034b9a0775a42b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 139MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5070b4a7c99a401d8fec714bc9e8b9ca"
          }
        },
        "ed556bd2978e465f8fbe98c565998f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a2a232c8cfe47fd95cb05fb814e7906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "560947e49c664a7b9034b9a0775a42b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5070b4a7c99a401d8fec714bc9e8b9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambekarsameer96/algonuts/blob/main/ResNet_for_AlgoNuts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbYXou6chZf",
        "outputId": "9690fa4c-f937-418b-d58e-9336a01bc9e3"
      },
      "source": [
        "!nvidia-smi\n",
        "!prime-select query"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 13 13:44:36 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "/bin/bash: prime-select: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQJAOOt-poWL",
        "outputId": "ffacfbae-c2a2-484c-eee2-eb53bf411e55"
      },
      "source": [
        "!prime-select query"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: prime-select: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAZLrMszV0mO"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-4CQwczprCD"
      },
      "source": [
        "# install libraries\n",
        "%%capture\n",
        "!pip install decord\n",
        "!pip install hickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKcF0Jq2Zb8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymxloMH7W9DJ"
      },
      "source": [
        "# **Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3_rDuziXB_L"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import time\n",
        "import tqdm\n",
        "import torch\n",
        "import IPython\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.models import ResNet\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-eImN-N8c5p"
      },
      "source": [
        "# image & video libraries\n",
        "from decord import VideoReader  \n",
        "from PIL import Image    \n",
        "\n",
        "# others\n",
        "import glob\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocvk88yg8cnv"
      },
      "source": [
        "from torch.autograd import Variable as V\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mrh5BKcuhYT"
      },
      "source": [
        "# random number generators for reproducibility\n",
        "seed = 24\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytHUJbt9XT14"
      },
      "source": [
        "# **Import and Define RESNET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rAVDRb8ZxxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "3bb8a48346fa4180a583b255351f4783",
            "881b4581a5514b98991a47a66337f26a",
            "525b00faca7e4a4891d9743b41dba189",
            "da029b3776ec4cd7b0cac2a303236ce6",
            "ed556bd2978e465f8fbe98c565998f92",
            "3a2a232c8cfe47fd95cb05fb814e7906",
            "560947e49c664a7b9034b9a0775a42b9",
            "5070b4a7c99a401d8fec714bc9e8b9ca"
          ]
        },
        "outputId": "80e16e38-94a4-4174-ca40-fb7b51076cff"
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "# torch.utils.model_zoo.load_url()\n",
        "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
        "# models.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bb8a48346fa4180a583b255351f4783",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46830571.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6BWqsEGVz1I"
      },
      "source": [
        "__all__ = ['ResNet', 'resnet18']\n",
        "model_url = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-f37072fd.pth'}\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 1000,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
        "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        out1 = self.conv1(x)\n",
        "        out2 = self.bn1(x)\n",
        "        out3 = self.relu(x)\n",
        "        out4 = self.maxpool(x)\n",
        "\n",
        "        out5 = self.layer1(x)\n",
        "        out6 = self.layer2(x)\n",
        "        out7 = self.layer3(x)\n",
        "        out8 = self.layer4(x)\n",
        "\n",
        "        out_avg = self.avgpool(x)\n",
        "        flat = torch.flatten(x, 1)\n",
        "        fin = self.fc(x)\n",
        "\n",
        "        return out1, out2, out3, out4, out5, out6, out7, out8, out_avg, flat, fin\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RsQas9puwtm"
      },
      "source": [
        "# **Load The Weights**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDGTh4X853zE"
      },
      "source": [
        "def load_model(model_url):\n",
        "    \"\"\"This function initializes a neural network (ResNet) and load\n",
        "    its weights from a pretrained model.\n",
        "    \n",
        "    Args:\n",
        "        arch: class\n",
        "            pytorch neural network.\n",
        "        model_url: str\n",
        "            pytorch model. \n",
        "\n",
        "    Returns:\n",
        "        model: class\n",
        "            pytorch model ready for inference.\n",
        "    \"\"\"\n",
        "\n",
        "    # instantiate model architecture\n",
        "    model = resnet18()\n",
        "    \n",
        "    # list of parameters name of the model\n",
        "    param_names = list(model.state_dict())  \n",
        "\n",
        "    # initialise dictionary of model parameters\n",
        "    model_dict = {k:None for k in param_names}\n",
        "\n",
        "    # load parameters of pretrained model\n",
        "    state_dict = hub.load_state_dict_from_url(model_url)\n",
        "    \n",
        "    i = 0\n",
        "    for v in state_dict.values():\n",
        "        model_dict[param_names[i]] = v\n",
        "        i += 1\n",
        "\n",
        "    model.load_state_dict(model_dict)\n",
        "\n",
        "    # set inference mode\n",
        "    model.eval()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcDv8hUg8yJB"
      },
      "source": [
        "def print_ResNet_Predictions(output):\n",
        "    with open('class_names_ImageNet.txt') as labels:\n",
        "        classes = [i.strip() for i in labels.readlines()]\n",
        "\n",
        "    # sort the probability vector in descending order\n",
        "    sorted, indices = torch.sort(output, descending=True)\n",
        "    percentage = F.softmax(output, dim=1)[0] * 100.0\n",
        "    \n",
        "    # obtain the first 5 classes (with the highest probability) the input belongs to\n",
        "    results = [(classes[i], percentage[i].item()) for i in indices[0][:5]]\n",
        "    for i in range(5):\n",
        "        print('{}: {:.4f}%'.format(results[i][0], results[i][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBdwhkUDaFac"
      },
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvfK0yjYaGg3",
        "outputId": "aad0a346-ea1d-474b-8148-f3fb8245d85f"
      },
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.5917e-02, -1.5497e+00,  3.2031e-01, -2.0585e+00, -8.5747e-01,\n",
            "         1.7843e+00,  1.4699e+00,  2.1626e+00,  4.4888e+00,  8.2885e-01,\n",
            "        -5.7819e+00, -3.4969e+00, -4.0621e+00, -4.7517e+00, -3.8072e+00,\n",
            "        -4.7243e+00, -1.2590e+00,  2.9813e-01, -2.0459e+00, -5.2885e-01,\n",
            "        -3.5982e+00, -8.1425e-01, -2.7651e+00, -1.2770e+00, -3.4182e+00,\n",
            "        -1.9048e+00, -3.0018e+00, -1.3471e+00, -1.8391e+00,  1.3937e+00,\n",
            "        -2.0114e+00, -1.4137e+00, -2.3287e+00, -1.8198e+00, -1.1914e-01,\n",
            "        -3.4102e+00, -1.6544e+00, -3.4496e+00, -2.6479e+00, -2.7407e+00,\n",
            "        -2.2193e+00, -3.6509e+00, -4.1255e+00, -5.5946e+00, -1.7519e+00,\n",
            "        -1.6900e+00, -9.8164e-01, -2.1251e+00, -3.5137e+00, -1.3320e+00,\n",
            "        -1.1335e+00, -1.1564e+00, -2.2711e-02, -8.5797e-01, -1.2919e+00,\n",
            "        -2.8682e+00,  6.6078e-01, -1.7178e+00, -1.2443e+00, -2.3362e+00,\n",
            "        -5.7817e-02, -1.9204e+00, -2.5964e+00, -1.8020e+00, -1.5125e+00,\n",
            "        -1.0843e+00, -4.0987e-01, -1.3090e+00, -9.4153e-01, -4.0615e+00,\n",
            "        -1.9027e+00, -6.0975e-01, -2.3426e+00, -2.5544e+00, -2.7568e+00,\n",
            "        -2.1587e+00, -3.0438e+00, -3.8201e+00,  1.9932e+00,  8.0768e-01,\n",
            "        -2.8857e+00, -4.6229e-01, -1.9095e+00, -1.8599e+00, -1.9991e-01,\n",
            "        -7.4707e-01, -2.3904e+00, -1.1250e+00, -2.0491e+00,  2.2938e+00,\n",
            "        -2.6377e+00, -3.6704e+00, -4.7520e+00, -2.8039e+00, -1.9299e+00,\n",
            "        -4.6468e+00, -2.5182e+00, -2.4850e+00, -3.0077e+00, -4.8836e-01,\n",
            "        -9.3521e-01, -2.6058e+00,  2.1376e+00, -2.6329e+00,  8.3506e+00,\n",
            "         8.9668e-01,  3.7531e+00, -3.4335e+00, -1.8960e+00, -4.2943e+00,\n",
            "         2.9082e-01, -2.3308e+00,  2.3836e+00,  4.2318e-02,  2.2397e-01,\n",
            "         7.5308e-01, -3.3080e+00, -1.4768e+00, -1.1792e+00, -1.9249e+00,\n",
            "        -1.8421e+00, -1.2775e+00, -1.0864e+00, -9.9565e-01,  1.5227e-01,\n",
            "        -1.4355e+00, -1.8052e+00,  1.0732e+00, -1.8634e+00,  2.6153e-01,\n",
            "        -1.5023e+00, -4.6530e+00, -1.9521e+00, -6.8744e+00, -1.6433e+00,\n",
            "        -3.2272e+00, -3.2739e+00, -3.8374e+00, -2.1751e+00, -3.5047e+00,\n",
            "        -4.7009e+00, -3.6270e+00, -4.8844e+00, -1.9901e+00,  2.6526e-01,\n",
            "        -6.7295e-01,  9.3509e-01, -2.2415e+00, -2.1363e+00, -4.7924e-01,\n",
            "        -2.6271e-01,  5.0756e+00,  4.4932e+00,  5.3031e+00,  5.1180e+00,\n",
            "         1.0446e+00,  5.5505e-02,  5.7181e+00,  2.8040e+00, -6.5413e-01,\n",
            "         7.1562e-01, -1.0806e+00, -8.4479e-01, -1.4036e+00, -4.8315e-01,\n",
            "        -4.0582e+00,  2.1611e-02, -1.7137e+00, -2.5360e-01,  5.0012e+00,\n",
            "         6.5730e+00,  3.8631e-01,  1.3999e-01,  3.1344e+00,  6.6824e+00,\n",
            "         2.2414e+00,  4.6645e-01,  3.2950e+00, -8.5229e-01,  1.1061e+00,\n",
            "         1.6826e+00,  2.9596e-02,  2.7676e+00,  1.0094e+00,  3.2906e+00,\n",
            "         6.0673e+00,  7.0698e+00,  5.1815e-01,  3.6306e+00,  2.7650e+00,\n",
            "         3.2205e+00, -9.3784e-01,  6.9483e+00,  4.2839e+00,  2.6159e+00,\n",
            "         1.6080e+00,  4.3847e-01,  1.0887e+00, -3.5319e-01,  6.1558e+00,\n",
            "         2.6472e+00,  1.6073e+00,  2.6772e+00,  1.0351e+01,  2.5268e+00,\n",
            "         8.3449e-01, -1.3505e+00,  5.1928e+00,  2.9642e+00, -5.6726e-01,\n",
            "        -1.4320e+00,  2.9362e-02,  2.4520e+00,  3.0417e-01, -7.7818e-01,\n",
            "         1.6603e+00,  1.9853e+00,  2.0598e+00,  2.6966e-01, -1.8801e-01,\n",
            "         2.7372e-01, -1.7507e+00,  8.8910e+00,  8.1109e+00,  7.3231e+00,\n",
            "         2.8657e+00,  3.7827e+00,  4.1981e+00,  5.8150e+00,  6.1472e+00,\n",
            "         6.4172e+00,  7.6086e+00,  6.9848e+00,  2.9936e+00, -5.2758e-01,\n",
            "         5.5965e+00,  1.4392e+00, -3.9503e-01,  2.0425e+00,  1.8702e+00,\n",
            "         2.0413e+00,  2.0422e-01,  6.4460e-01, -4.0614e-01,  2.5661e+00,\n",
            "         1.2417e+00,  1.4611e+00,  4.1676e+00,  1.0818e+01,  8.7367e+00,\n",
            "         9.9064e+00,  2.8385e+00,  2.0287e-01,  1.7976e+00,  2.3186e+00,\n",
            "         2.5285e+00,  4.5001e+00,  1.1026e+01,  1.6273e+01,  1.1215e+01,\n",
            "         7.8094e+00,  1.0740e+01, -9.9217e-02,  5.7142e+00,  4.7237e+00,\n",
            "         3.3941e+00,  3.0939e+00,  3.8398e+00, -8.0394e-01,  8.1740e+00,\n",
            "         1.3279e+01,  3.4679e+00,  4.4451e+00,  5.5244e+00,  4.1509e+00,\n",
            "        -1.9327e-01,  1.3198e+00,  5.0951e+00,  4.9228e+00,  1.3313e+01,\n",
            "         4.6688e+00,  4.1280e+00,  3.8479e+00,  6.4162e+00,  6.1095e+00,\n",
            "         3.3097e+00,  2.3572e+00,  6.8445e+00,  9.5434e-01,  2.8592e+00,\n",
            "        -1.1244e+00,  1.5085e+00,  1.7631e+00,  1.2531e+00,  2.8554e+00,\n",
            "         1.7463e+00,  6.7799e+00,  2.5125e-01, -1.3342e+00,  5.1050e-01,\n",
            "        -2.8969e+00, -8.2496e-01, -2.9130e+00, -3.0456e+00, -1.1142e+00,\n",
            "        -2.8026e+00, -1.4486e+00, -6.7262e-01, -4.2247e+00, -1.7623e+00,\n",
            "         4.3570e-01, -1.4014e+00, -1.5380e+00, -1.5596e+00,  1.6334e+00,\n",
            "        -2.3892e+00, -2.9759e+00, -4.3734e-01, -5.5001e-01, -6.1542e+00,\n",
            "        -4.0857e+00, -2.3556e+00, -3.9536e+00, -2.8767e+00, -4.4984e-01,\n",
            "        -1.7370e+00, -1.6374e+00,  2.1360e+00, -8.5107e-01, -1.5194e-02,\n",
            "         2.7704e+00,  5.3773e+00,  5.9535e+00,  5.4208e+00,  2.8854e+00,\n",
            "         3.7443e-01,  1.6293e+00,  4.4487e-01,  3.2411e+00,  9.7582e-01,\n",
            "         2.5310e-02,  3.1032e+00, -2.7099e-01, -2.7836e+00, -3.1692e+00,\n",
            "         8.1343e-01, -6.5196e-01, -2.9631e+00,  2.6037e+00, -9.6922e-01,\n",
            "        -9.5742e-01, -4.7068e+00, -3.5804e+00,  2.2840e-01, -2.1702e+00,\n",
            "         6.5002e+00,  5.7219e+00,  2.9793e+00,  6.4611e+00,  5.4975e+00,\n",
            "        -5.2996e-01,  4.7048e+00,  2.8008e+00, -3.6109e-03, -1.3491e+00,\n",
            "        -4.5432e-01, -5.6187e-01, -1.6322e+00,  2.1284e+00, -1.4569e+00,\n",
            "        -1.1618e-03,  9.0620e-01,  1.6598e+00,  2.0624e+00,  1.0829e+00,\n",
            "        -8.1911e-01, -3.6819e+00,  2.5470e+00,  1.4180e+00,  5.3964e-01,\n",
            "         1.0845e+00, -9.6097e-02,  4.6213e-01,  1.0754e+00,  7.6537e-02,\n",
            "        -2.6620e+00, -4.3084e+00,  3.6672e+00,  5.1774e+00, -6.1791e-01,\n",
            "        -1.5415e+00,  7.3573e-01, -3.7433e+00, -2.9970e+00, -5.4823e-01,\n",
            "        -1.9206e+00, -3.7729e+00, -2.9885e+00, -9.2415e-01, -4.2514e-01,\n",
            "        -8.8965e-01, -5.8486e-01, -6.5334e-01, -4.9157e+00, -2.8375e+00,\n",
            "         3.4268e-01, -2.2503e+00, -2.7347e-01, -2.4050e+00, -5.2626e-01,\n",
            "        -2.6042e+00,  3.2445e-01,  4.0667e+00, -2.1196e+00, -5.1543e-01,\n",
            "        -1.7745e+00, -2.0623e+00, -6.6496e-01, -1.4364e+00,  9.8571e-01,\n",
            "         5.9961e-03, -9.6792e-01, -6.0225e-01, -1.4000e+00, -2.0710e+00,\n",
            "         1.1075e+00, -1.9486e+00,  2.2065e+00,  2.9293e+00,  1.8658e+00,\n",
            "        -2.8881e+00, -4.3115e-01, -1.3990e+00, -3.7418e-01,  7.7500e-01,\n",
            "         3.9198e+00, -7.5727e-01, -1.8530e-01, -1.6255e+00,  2.2081e+00,\n",
            "         1.5956e+00,  6.9977e-02,  3.9039e-01,  4.6344e-01,  5.9016e-01,\n",
            "        -9.2834e-02, -5.1500e-01, -1.3637e+00, -1.5078e-01, -5.6912e-01,\n",
            "         2.4666e+00, -1.7132e+00, -1.6860e+00, -3.2602e-01, -8.4201e-01,\n",
            "         2.1154e+00, -8.4047e-02,  1.7860e+00, -6.3439e-01, -7.4765e-01,\n",
            "         4.2897e-01, -5.1184e-01,  3.4125e+00,  5.7139e+00, -1.2795e+00,\n",
            "        -1.6497e+00, -2.5285e+00, -3.1734e+00, -1.0102e+00,  9.4760e-01,\n",
            "         9.9308e-01, -1.0922e-01,  2.5839e+00,  1.4922e+00, -1.2992e+00,\n",
            "        -2.8170e-01, -8.6435e-01, -1.4672e-01,  1.7313e+00,  2.4510e+00,\n",
            "        -7.3570e-01, -2.5554e+00, -1.9142e+00,  1.6980e-01,  3.2632e-01,\n",
            "        -1.3443e+00, -1.5297e+00, -7.6557e-01, -7.8684e-01,  1.0074e+00,\n",
            "        -1.2130e+00,  1.4810e+00, -2.7207e-01, -1.3605e+00, -1.7983e-01,\n",
            "        -1.1730e+00,  2.3959e+00, -6.8000e-01, -2.6903e+00,  7.7481e-02,\n",
            "        -3.4509e+00,  1.2124e+00,  1.2672e+00, -1.0999e+00,  2.8033e-01,\n",
            "        -9.9974e-01, -2.0026e+00,  7.5466e-01,  2.4307e+00, -1.7247e+00,\n",
            "        -7.9773e-02,  8.8518e-01, -4.0756e-01, -2.4663e+00, -1.2027e+00,\n",
            "         5.4814e-01, -1.6021e+00, -2.4280e+00,  5.5575e-01, -3.8049e-01,\n",
            "        -2.0516e+00,  3.3770e+00,  3.1902e+00,  6.7000e-01, -6.8531e-01,\n",
            "        -9.4827e-01, -3.6431e-01, -7.6098e-01,  2.1828e+00,  8.0119e-01,\n",
            "        -1.0046e+00, -1.2824e+00, -2.3656e+00, -3.1687e+00,  2.1272e+00,\n",
            "         1.2671e-01, -1.6892e+00,  2.6973e+00, -3.0822e+00,  4.0324e+00,\n",
            "        -2.8332e+00,  3.3901e-01,  1.0081e-02,  5.2545e-01,  1.9752e+00,\n",
            "        -7.1674e-02,  2.9041e-01, -2.9111e+00, -2.4014e+00,  7.0131e-01,\n",
            "        -4.1842e+00,  4.7370e-01,  1.1472e+00, -6.1524e-01, -7.0896e-01,\n",
            "        -3.9985e-01, -3.3715e-01, -6.5772e-01, -2.2189e+00,  1.5345e+00,\n",
            "         1.2745e+00,  2.7751e-01, -2.2735e+00, -5.5896e-01, -3.7202e+00,\n",
            "        -2.9080e+00, -6.8846e-01,  9.7099e-02,  1.8662e+00, -8.5188e-01,\n",
            "        -8.4573e-01, -3.8525e+00,  3.4325e-01,  2.5432e-01,  2.6882e+00,\n",
            "         2.5991e-01, -2.0000e+00,  5.3708e-01,  1.0960e+00, -1.3279e+00,\n",
            "         1.4837e+00, -5.9336e-01, -2.0439e+00, -1.2371e+00,  1.0513e+00,\n",
            "         6.4954e-01, -6.2647e-02,  1.2370e+00,  6.8368e-01,  3.8259e+00,\n",
            "        -1.7971e+00, -6.7278e-01, -2.5600e+00, -1.6512e+00,  1.1806e+00,\n",
            "        -1.2924e+00,  2.2586e+00, -4.0487e-01, -1.1882e+00, -2.3765e+00,\n",
            "         7.9954e-01, -9.1990e-01, -1.6126e+00, -1.9355e+00, -3.9238e+00,\n",
            "        -2.1017e+00,  2.1352e+00, -2.5646e-01,  4.8958e-01, -6.0499e-01,\n",
            "         1.1564e+00,  1.8465e+00, -4.0932e+00,  2.7047e-01, -2.1523e-01,\n",
            "         1.3753e+00, -1.4033e+00, -1.0388e+00,  4.7860e-02, -1.2729e-01,\n",
            "         3.2859e-01,  1.8630e+00,  3.2699e+00, -3.5368e-01, -2.1416e+00,\n",
            "        -4.3183e-01,  7.7666e-01,  3.7305e-02, -2.0635e+00,  3.1161e-01,\n",
            "         1.6417e+00,  2.6682e+00,  2.7170e-01,  8.3578e-01, -2.9818e+00,\n",
            "        -2.4503e-01,  2.4742e-01,  1.3297e-01, -4.3418e-01, -4.3046e-01,\n",
            "         6.5773e-01,  2.1311e+00, -3.2655e+00, -5.1050e-01,  4.9344e-01,\n",
            "        -1.8940e+00,  1.8291e+00, -1.6717e+00,  6.3228e-01, -1.6439e+00,\n",
            "        -1.6570e+00, -1.1218e-03, -6.8659e-01,  2.0163e+00, -4.9133e-01,\n",
            "         7.9273e-01, -6.5997e-01, -1.4483e+00,  5.7451e-01,  2.2929e-01,\n",
            "        -3.0037e-01, -2.0798e+00, -9.1574e-01, -1.9492e+00,  8.3745e-01,\n",
            "         1.2692e+00, -9.1458e-01,  5.4567e-01, -3.6889e+00, -9.1367e-01,\n",
            "         1.9861e+00, -2.5311e-01,  2.8521e-01,  2.0949e+00,  1.2086e+00,\n",
            "         2.1154e-01,  3.4622e+00,  9.5274e-02, -8.0216e-01,  2.7265e-01,\n",
            "         1.2197e+00,  7.2029e-01, -2.8354e+00, -2.7143e+00,  4.7934e-01,\n",
            "        -1.8512e+00,  2.9761e-01, -4.1026e+00,  1.8249e-01, -7.9936e-01,\n",
            "        -1.7338e+00, -9.6721e-01, -5.8128e-01, -8.2822e-01, -9.8596e-02,\n",
            "        -5.0435e-01,  1.5545e+00,  1.4904e+00, -1.2979e+00, -1.0826e-01,\n",
            "         2.9883e+00, -1.3630e+00, -3.7239e+00,  9.1957e-01, -2.5768e+00,\n",
            "        -3.0649e+00,  1.3365e+00, -1.4009e+00, -3.5322e-01, -1.1704e+00,\n",
            "        -7.4978e-01, -2.5903e-01, -6.0259e-01, -1.5579e+00,  1.3899e+00,\n",
            "        -2.3793e+00,  1.9803e+00,  3.3006e-01, -1.0206e-01,  2.4416e+00,\n",
            "         1.2657e+00, -6.6137e-01,  2.2869e+00,  1.8482e+00, -2.9063e+00,\n",
            "        -5.7494e-01, -5.1072e+00, -2.6364e+00,  2.1372e+00, -1.3472e+00,\n",
            "        -2.2591e+00,  4.3973e+00, -2.2593e+00, -1.0246e+00, -3.2030e+00,\n",
            "         6.7143e-01, -1.9926e+00, -2.0654e-01,  4.0617e-01, -2.9339e+00,\n",
            "         1.5753e+00, -9.1893e-01,  1.1542e+00, -9.1348e-01, -1.2591e+00,\n",
            "        -1.9500e+00,  1.0347e+00,  8.3912e-01,  1.6410e+00,  1.3352e+00,\n",
            "         7.9203e-01,  7.8801e-01,  1.2226e+00,  1.3795e+00, -7.8040e-01,\n",
            "        -1.3666e+00,  5.3833e+00,  5.1337e-01,  4.9046e-01,  5.2560e-01,\n",
            "         7.3350e-01,  2.2732e+00, -1.3203e+00,  9.3211e-01, -1.6302e+00,\n",
            "         2.4191e-01, -2.4871e-01, -4.8620e-01,  2.1138e+00,  1.4489e+00,\n",
            "         3.7367e-01,  1.4004e+00,  1.5152e+00, -3.6104e-01,  2.9181e-01,\n",
            "        -9.4115e-01, -2.2436e+00, -4.9276e-01, -4.5846e-01, -2.1174e+00,\n",
            "        -2.6535e+00, -4.2171e-01,  1.4914e+00,  6.6903e-01,  1.0808e+00,\n",
            "        -2.9792e-01,  1.3667e+00,  7.1145e-01,  2.7971e-01,  3.5887e-02,\n",
            "        -1.5736e+00,  6.9128e-01,  1.3083e+00, -6.9339e-01,  8.5358e-02,\n",
            "        -4.8842e-01, -1.4164e+00,  2.3650e+00, -8.0814e-01,  7.6429e-01,\n",
            "        -4.9398e+00, -6.1574e-01, -4.6486e-01, -2.4251e+00,  1.1547e+00,\n",
            "         6.3762e+00,  9.0707e-01, -4.1598e-01, -1.3366e+00,  2.3717e-01,\n",
            "         1.4613e+00,  2.6383e+00, -1.3068e+00,  8.5315e-01, -3.5893e-01,\n",
            "        -9.9009e-01, -1.2835e+00,  5.5976e-01,  2.0846e-02, -8.9666e-01,\n",
            "        -6.9401e-01, -1.9417e+00, -6.7528e-01,  1.2534e+00,  1.3382e+00,\n",
            "         8.7609e-01, -4.7605e-01,  1.7552e+00,  5.1028e-01, -1.3920e+00,\n",
            "        -8.7654e-01,  1.1599e+00, -1.0186e+00, -1.3284e+00, -3.7167e-01,\n",
            "        -1.0469e+00,  5.7449e-01,  1.5574e+00,  1.8519e+00, -4.1095e-01,\n",
            "        -2.0581e-01,  1.0532e+00,  1.8591e+00,  4.5595e-01,  9.1578e-01,\n",
            "         1.1539e+00, -1.4320e+00, -5.3197e-01, -1.4754e+00, -1.0053e+00,\n",
            "         1.2264e+00,  1.5214e+00,  5.0184e+00, -1.5203e+00, -5.4168e-01,\n",
            "        -6.5428e-01, -1.8737e+00, -3.6343e+00, -1.0429e+00,  7.0411e-02,\n",
            "        -2.3703e+00,  2.4605e+00, -1.3011e-01, -1.7982e+00, -7.5531e-01,\n",
            "        -1.0359e+00, -1.3380e+00, -2.9617e-01, -8.2643e-01,  2.7119e-01,\n",
            "         1.5884e+00, -7.2462e-01, -2.9711e-01, -9.3042e-01, -2.4289e+00,\n",
            "        -9.2284e-01,  4.7528e+00, -1.6790e+00,  8.6679e-01,  7.8210e-01,\n",
            "         1.6629e+00, -1.0685e+00,  1.3574e+00, -8.2427e-01, -1.9540e+00,\n",
            "         4.4793e-01, -2.2733e+00, -1.9748e+00, -1.3135e+00,  7.5046e-02,\n",
            "        -6.2614e-01, -1.2929e+00, -7.9225e-01,  1.4181e-01, -5.3668e-01,\n",
            "        -3.7515e+00,  2.5790e+00,  2.9517e+00,  1.1170e+00, -7.2463e-02,\n",
            "        -1.0601e+00,  1.7500e-01,  1.4925e+00, -1.3864e+00,  1.2885e+00,\n",
            "        -1.8532e+00, -2.2471e+00,  2.7473e-01, -2.0507e+00, -5.4335e-01,\n",
            "         8.9407e-01,  7.9924e-01,  1.3935e+00, -1.7301e-01, -5.9534e-01,\n",
            "         8.0483e-01, -1.3372e-01, -3.2294e+00, -2.1450e-01, -1.5620e+00,\n",
            "        -2.2868e+00, -3.0804e-01, -4.4390e+00, -6.2412e-01, -2.5382e+00,\n",
            "        -2.4722e+00, -3.3123e+00, -2.8575e+00, -2.9188e+00,  3.9108e+00,\n",
            "        -2.2020e+00, -2.0254e+00, -5.1858e-01, -4.8108e+00, -2.6819e+00,\n",
            "         7.0437e-01, -3.2433e-01,  8.4757e-01,  1.2196e+00,  1.4949e+00,\n",
            "        -1.9164e+00, -3.8725e+00, -4.3444e-01,  2.0204e+00, -2.2128e+00,\n",
            "        -3.7765e+00, -3.2417e+00, -1.0154e+00,  1.8904e+00,  4.7872e-01,\n",
            "        -2.6042e+00, -2.1485e+00, -2.8178e+00, -1.2955e+00, -1.0276e+00,\n",
            "        -2.7621e+00, -1.6165e+00, -4.1203e-01, -1.9367e-01, -2.4879e+00,\n",
            "        -1.3851e+00,  7.6087e-01, -2.6262e+00, -2.1398e+00, -5.1703e+00,\n",
            "        -2.3795e+00, -4.5068e-01, -4.3725e+00, -2.3892e-01, -8.7406e-01,\n",
            "         4.7021e-01,  1.5145e+00, -1.1402e+00, -3.5778e+00, -1.3159e-01,\n",
            "         2.2065e+00, -1.6685e+00,  7.5954e-01, -1.0781e+00, -7.7719e-01,\n",
            "        -6.3171e-01,  1.1631e-01,  1.1369e+00, -1.4187e+00, -8.3359e-01,\n",
            "        -1.6156e+00, -2.2305e+00,  6.9370e-01, -3.4886e+00, -1.4845e+00,\n",
            "        -1.3031e+00, -1.8285e-01, -5.2394e-01, -5.7335e+00, -1.8339e+00,\n",
            "        -6.5606e-01, -1.8088e+00, -2.9126e+00,  5.6032e-01,  2.5117e+00],\n",
            "       device='cuda:0')\n",
            "tensor([7.6952e-08, 1.6081e-08, 1.0433e-07, 9.6676e-09, 3.2130e-08, 4.5104e-07,\n",
            "        3.2936e-07, 6.5847e-07, 6.7416e-06, 1.7349e-07, 2.3349e-10, 2.2942e-09,\n",
            "        1.3037e-09, 6.5414e-10, 1.6821e-09, 6.7231e-10, 2.1504e-08, 1.0204e-07,\n",
            "        9.7904e-09, 4.4630e-08, 2.0732e-09, 3.3550e-08, 4.7693e-09, 2.1121e-08,\n",
            "        2.4821e-09, 1.1274e-08, 3.7640e-09, 1.9692e-08, 1.2039e-08, 3.0521e-07,\n",
            "        1.0133e-08, 1.8423e-08, 7.3788e-09, 1.2274e-08, 6.7231e-08, 2.5019e-09,\n",
            "        1.4481e-08, 2.4052e-09, 5.3622e-09, 4.8868e-09, 8.2313e-09, 1.9667e-09,\n",
            "        1.2236e-09, 2.8159e-10, 1.3136e-08, 1.3975e-08, 2.8378e-08, 9.0447e-09,\n",
            "        2.2558e-09, 1.9991e-08, 2.4380e-08, 2.3829e-08, 7.4037e-08, 3.2114e-08,\n",
            "        2.0808e-08, 4.3020e-09, 1.4665e-07, 1.3592e-08, 2.1822e-08, 7.3231e-09,\n",
            "        7.1482e-08, 1.1099e-08, 5.6456e-09, 1.2495e-08, 1.6690e-08, 2.5611e-08,\n",
            "        5.0270e-08, 2.0456e-08, 2.9540e-08, 1.3045e-09, 1.1297e-08, 4.1162e-08,\n",
            "        7.2767e-09, 5.8878e-09, 4.8088e-09, 8.7458e-09, 3.6092e-09, 1.6606e-09,\n",
            "        5.5582e-07, 1.6986e-07, 4.2273e-09, 4.7702e-08, 1.1221e-08, 1.1791e-08,\n",
            "        6.2014e-08, 3.5881e-08, 6.9368e-09, 2.4589e-08, 9.7591e-09, 7.5075e-07,\n",
            "        5.4170e-09, 1.9288e-09, 6.5393e-10, 4.5878e-09, 1.0994e-08, 7.2648e-10,\n",
            "        6.1046e-09, 6.3108e-09, 3.7417e-09, 4.6475e-08, 2.9727e-08, 5.5929e-09,\n",
            "        6.4218e-07, 5.4434e-09, 3.2057e-04, 1.8567e-07, 3.2303e-06, 2.4443e-09,\n",
            "        1.1373e-08, 1.0335e-09, 1.0130e-07, 7.3633e-09, 8.2131e-07, 7.9011e-08,\n",
            "        9.4750e-08, 1.6083e-07, 2.7711e-09, 1.7296e-08, 2.3292e-08, 1.1049e-08,\n",
            "        1.2003e-08, 2.1110e-08, 2.5556e-08, 2.7984e-08, 8.8194e-08, 1.8025e-08,\n",
            "        1.2454e-08, 2.2151e-07, 1.1750e-08, 9.8376e-08, 1.6861e-08, 7.2198e-10,\n",
            "        1.0752e-08, 7.8303e-11, 1.4643e-08, 3.0045e-09, 2.8674e-09, 1.6322e-09,\n",
            "        8.6031e-09, 2.2764e-09, 6.8824e-10, 2.0143e-09, 5.7286e-10, 1.0352e-08,\n",
            "        9.8744e-08, 3.8641e-08, 1.9294e-07, 8.0510e-09, 8.9437e-09, 4.6901e-08,\n",
            "        5.8239e-08, 1.2124e-05, 6.7712e-06, 1.5220e-05, 1.2648e-05, 2.1527e-07,\n",
            "        8.0060e-08, 2.3050e-05, 1.2505e-06, 3.9375e-08, 1.5492e-07, 2.5704e-08,\n",
            "        3.2540e-08, 1.8609e-08, 4.6718e-08, 1.3088e-09, 7.7392e-08, 1.3648e-08,\n",
            "        5.8772e-08, 1.1254e-05, 5.4192e-05, 1.1145e-07, 8.7117e-08, 1.7401e-06,\n",
            "        6.0454e-05, 7.1243e-07, 1.2075e-07, 2.0431e-06, 3.2297e-08, 2.2893e-07,\n",
            "        4.0745e-07, 7.8012e-08, 1.2057e-06, 2.0782e-07, 2.0343e-06, 3.2683e-05,\n",
            "        8.9056e-05, 1.2716e-07, 2.8581e-06, 1.2026e-06, 1.8966e-06, 2.9649e-08,\n",
            "        7.8874e-05, 5.4927e-06, 1.0361e-06, 3.7813e-07, 1.1742e-07, 2.2497e-07,\n",
            "        5.3201e-08, 3.5705e-05, 1.0690e-06, 3.7789e-07, 1.1016e-06, 2.3704e-03,\n",
            "        9.4771e-07, 1.7447e-07, 1.9624e-08, 1.3630e-05, 1.4677e-06, 4.2949e-08,\n",
            "        1.8088e-08, 7.7994e-08, 8.7944e-07, 1.0266e-07, 3.4782e-08, 3.9846e-07,\n",
            "        5.5148e-07, 5.9410e-07, 9.9179e-08, 6.2757e-08, 9.9582e-08, 1.3152e-08,\n",
            "        5.5033e-04, 2.5226e-04, 1.1473e-04, 1.3300e-06, 3.3273e-06, 5.0411e-06,\n",
            "        2.5394e-05, 3.5401e-05, 4.6372e-05, 1.5265e-04, 8.1799e-05, 1.5115e-06,\n",
            "        4.4687e-08, 2.0411e-05, 3.1942e-07, 5.1021e-08, 5.8395e-07, 4.9148e-07,\n",
            "        5.8321e-07, 9.2896e-08, 1.4430e-07, 5.0458e-08, 9.8570e-07, 2.6215e-07,\n",
            "        3.2649e-07, 4.8896e-06, 3.7817e-03, 4.7163e-04, 1.5191e-03, 1.2944e-06,\n",
            "        9.2772e-08, 4.5708e-07, 7.6959e-07, 9.4933e-07, 6.8182e-06, 4.6520e-03,\n",
            "        8.8462e-01, 5.6213e-03, 1.8660e-04, 3.4972e-03, 6.8584e-08, 2.2959e-05,\n",
            "        8.5271e-06, 2.2560e-06, 1.6710e-06, 3.5232e-06, 3.3897e-08, 2.6867e-04,\n",
            "        4.4276e-02, 2.4287e-06, 6.4532e-06, 1.8991e-05, 4.8086e-06, 6.2427e-08,\n",
            "        2.8345e-07, 1.2362e-05, 1.0406e-05, 4.5805e-02, 8.0716e-06, 4.6998e-06,\n",
            "        3.5515e-06, 4.6326e-05, 3.4091e-05, 2.0734e-06, 7.9991e-07, 7.1097e-05,\n",
            "        1.9669e-07, 1.3215e-06, 2.4602e-08, 3.4234e-07, 4.4160e-07, 2.6518e-07,\n",
            "        1.3164e-06, 4.3421e-07, 6.6649e-05, 9.7370e-08, 1.9947e-08, 1.2619e-07,\n",
            "        4.1800e-09, 3.3192e-08, 4.1135e-09, 3.6025e-09, 2.4855e-08, 4.5934e-09,\n",
            "        1.7790e-08, 3.8654e-08, 1.1080e-09, 1.3000e-08, 1.1709e-07, 1.8651e-08,\n",
            "        1.6270e-08, 1.5922e-08, 3.8787e-07, 6.9450e-09, 3.8629e-09, 4.8908e-08,\n",
            "        4.3696e-08, 1.6091e-10, 1.2733e-09, 7.1830e-09, 1.4531e-09, 4.2657e-09,\n",
            "        4.8300e-08, 1.3334e-08, 1.4730e-08, 6.4116e-07, 3.2337e-08, 7.4595e-08,\n",
            "        1.2091e-06, 1.6392e-05, 2.9166e-05, 1.7121e-05, 1.3565e-06, 1.1013e-07,\n",
            "        3.8627e-07, 1.1817e-07, 1.9361e-06, 2.0096e-07, 7.7679e-08, 1.6867e-06,\n",
            "        5.7759e-08, 4.6816e-09, 3.1838e-09, 1.7083e-07, 3.9461e-08, 3.9123e-09,\n",
            "        1.0235e-06, 2.8733e-08, 2.9074e-08, 6.8419e-10, 2.1105e-09, 9.5171e-08,\n",
            "        8.6461e-09, 5.0385e-05, 2.3136e-05, 1.4900e-06, 4.8456e-05, 1.8486e-05,\n",
            "        4.4581e-08, 8.3668e-06, 1.2465e-06, 7.5464e-08, 1.9652e-08, 4.8084e-08,\n",
            "        4.3181e-08, 1.4806e-08, 6.3628e-07, 1.7643e-08, 7.5649e-08, 1.8744e-07,\n",
            "        3.9823e-07, 5.9566e-07, 2.2366e-07, 3.3387e-08, 1.9067e-09, 9.6707e-07,\n",
            "        3.1272e-07, 1.2992e-07, 2.2403e-07, 6.8798e-08, 1.2023e-07, 2.2199e-07,\n",
            "        8.1761e-08, 5.2871e-09, 1.0190e-09, 2.9646e-06, 1.3422e-05, 4.0827e-08,\n",
            "        1.6212e-08, 1.5806e-07, 1.7931e-09, 3.7820e-09, 4.3774e-08, 1.1097e-08,\n",
            "        1.7408e-09, 3.8143e-09, 3.0058e-08, 4.9508e-08, 3.1113e-08, 4.2200e-08,\n",
            "        3.9406e-08, 5.5520e-10, 4.4359e-09, 1.0669e-07, 7.9804e-09, 5.7616e-08,\n",
            "        6.8366e-09, 4.4746e-08, 5.6015e-09, 1.0476e-07, 4.4204e-06, 9.0948e-09,\n",
            "        4.5234e-08, 1.2843e-08, 9.6311e-09, 3.8951e-08, 1.8009e-08, 2.0295e-07,\n",
            "        7.6193e-08, 2.8770e-08, 4.1472e-08, 1.8677e-08, 9.5471e-09, 2.2923e-07,\n",
            "        1.0790e-08, 6.8799e-07, 1.4175e-06, 4.8934e-07, 4.2172e-09, 4.9211e-08,\n",
            "        1.8696e-08, 5.2096e-08, 1.6440e-07, 3.8163e-06, 3.5517e-08, 6.2927e-08,\n",
            "        1.4907e-08, 6.8912e-07, 3.7347e-07, 8.1227e-08, 1.1191e-07, 1.2039e-07,\n",
            "        1.3665e-07, 6.9023e-08, 4.5253e-08, 1.9367e-08, 6.5137e-08, 4.2869e-08,\n",
            "        8.9237e-07, 1.3655e-08, 1.4030e-08, 5.4666e-08, 3.2631e-08, 6.2811e-07,\n",
            "        6.9632e-08, 4.5184e-07, 4.0160e-08, 3.5860e-08, 1.1631e-07, 4.5396e-08,\n",
            "        2.2979e-06, 2.2952e-05, 2.1068e-08, 1.4549e-08, 6.0421e-09, 3.1703e-09,\n",
            "        2.7580e-08, 1.9536e-07, 2.0446e-07, 6.7901e-08, 1.0035e-06, 3.3680e-07,\n",
            "        2.0658e-08, 5.7144e-08, 3.1910e-08, 6.5401e-08, 4.2775e-07, 8.7858e-07,\n",
            "        3.6291e-08, 5.8816e-09, 1.1168e-08, 8.9754e-08, 1.0496e-07, 1.9747e-08,\n",
            "        1.6404e-08, 3.5223e-08, 3.4482e-08, 2.0741e-07, 2.2517e-08, 3.3304e-07,\n",
            "        5.7697e-08, 1.9429e-08, 6.3272e-08, 2.3435e-08, 8.3142e-07, 3.8370e-08,\n",
            "        5.1397e-09, 8.1839e-08, 2.4021e-09, 2.5460e-07, 2.6894e-07, 2.5213e-08,\n",
            "        1.0024e-07, 2.7870e-08, 1.0223e-08, 1.6108e-07, 8.6088e-07, 1.3499e-08,\n",
            "        6.9930e-08, 1.8354e-07, 5.0386e-08, 6.4302e-09, 2.2750e-08, 1.3103e-07,\n",
            "        1.5259e-08, 6.6810e-09, 1.3203e-07, 5.1768e-08, 9.7349e-09, 2.2177e-06,\n",
            "        1.8400e-06, 1.4801e-07, 3.8167e-08, 2.9341e-08, 5.2613e-08, 3.5385e-08,\n",
            "        6.7187e-07, 1.6876e-07, 2.7735e-08, 2.1007e-08, 7.1109e-09, 3.1855e-09,\n",
            "        6.3554e-07, 8.5969e-08, 1.3986e-08, 1.1239e-06, 3.4731e-09, 4.2715e-06,\n",
            "        4.4552e-09, 1.0630e-07, 7.6505e-08, 1.2809e-07, 5.4594e-07, 7.0499e-08,\n",
            "        1.0126e-07, 4.1211e-09, 6.8611e-09, 1.5272e-07, 1.1538e-09, 1.2163e-07,\n",
            "        2.3852e-07, 4.0937e-08, 3.7275e-08, 5.0776e-08, 5.4061e-08, 3.9234e-08,\n",
            "        8.2350e-09, 3.5136e-07, 2.7092e-07, 9.9961e-08, 7.7971e-09, 4.3307e-08,\n",
            "        1.8350e-09, 4.1342e-09, 3.8046e-08, 8.3460e-08, 4.8952e-07, 3.2311e-08,\n",
            "        3.2510e-08, 1.6076e-09, 1.0675e-07, 9.7670e-08, 1.1137e-06, 9.8217e-08,\n",
            "        1.0250e-08, 1.2959e-07, 2.2663e-07, 2.0074e-08, 3.3393e-07, 4.1843e-08,\n",
            "        9.8101e-09, 2.1982e-08, 2.1672e-07, 1.4501e-07, 7.1138e-08, 2.6094e-07,\n",
            "        1.5005e-07, 3.4744e-06, 1.2556e-08, 3.8648e-08, 5.8549e-09, 1.4528e-08,\n",
            "        2.4662e-07, 2.0797e-08, 7.2481e-07, 5.0521e-08, 2.3083e-08, 7.0340e-09,\n",
            "        1.6848e-07, 3.0186e-08, 1.5100e-08, 1.0933e-08, 1.4971e-09, 9.2587e-09,\n",
            "        6.4063e-07, 5.8604e-08, 1.2358e-07, 4.1359e-08, 2.4072e-07, 4.7998e-07,\n",
            "        1.2637e-09, 9.9260e-08, 6.1071e-08, 2.9964e-07, 1.8615e-08, 2.6801e-08,\n",
            "        7.9450e-08, 6.6685e-08, 1.0520e-07, 4.8797e-07, 1.9925e-06, 5.3175e-08,\n",
            "        8.8970e-09, 4.9178e-08, 1.6467e-07, 7.8616e-08, 9.6197e-09, 1.0343e-07,\n",
            "        3.9110e-07, 1.0916e-06, 9.9382e-08, 1.7470e-07, 3.8398e-09, 5.9278e-08,\n",
            "        9.6998e-08, 8.6508e-08, 4.9062e-08, 4.9245e-08, 1.4620e-07, 6.3801e-07,\n",
            "        2.8914e-09, 4.5457e-08, 1.2405e-07, 1.1396e-08, 4.7170e-07, 1.4233e-08,\n",
            "        1.4253e-07, 1.4634e-08, 1.4444e-08, 7.5652e-08, 3.8118e-08, 5.6882e-07,\n",
            "        4.6337e-08, 1.6734e-07, 3.9146e-08, 1.7795e-08, 1.3453e-07, 9.5255e-08,\n",
            "        5.6087e-08, 9.4642e-09, 3.0311e-08, 1.0784e-08, 1.7499e-07, 2.6946e-07,\n",
            "        3.0347e-08, 1.3070e-07, 1.8935e-09, 3.0374e-08, 5.5188e-07, 5.8801e-08,\n",
            "        1.0073e-07, 6.1531e-07, 2.5362e-07, 9.3579e-08, 2.4150e-06, 8.3308e-08,\n",
            "        3.3957e-08, 9.9476e-08, 2.5645e-07, 1.5564e-07, 4.4455e-09, 5.0178e-09,\n",
            "        1.2232e-07, 1.1894e-08, 1.0199e-07, 1.2519e-09, 9.0900e-08, 3.4053e-08,\n",
            "        1.3376e-08, 2.8791e-08, 4.2351e-08, 3.3084e-08, 6.8626e-08, 4.5738e-08,\n",
            "        3.5843e-07, 3.3618e-07, 2.0683e-08, 6.7966e-08, 1.5036e-06, 1.9381e-08,\n",
            "        1.8283e-09, 1.8996e-07, 5.7573e-09, 3.5337e-09, 2.8824e-07, 1.8660e-08,\n",
            "        5.3199e-08, 2.3497e-08, 3.5784e-08, 5.8454e-08, 4.1458e-08, 1.5949e-08,\n",
            "        3.0405e-07, 7.0147e-09, 5.4873e-07, 1.0535e-07, 6.8389e-08, 8.7034e-07,\n",
            "        2.6855e-07, 3.9091e-08, 7.4557e-07, 4.8079e-07, 4.1412e-09, 4.2620e-08,\n",
            "        4.5844e-10, 5.4241e-09, 6.4190e-07, 1.9688e-08, 7.9102e-09, 6.1520e-06,\n",
            "        7.9086e-09, 2.7185e-08, 3.0780e-09, 1.4822e-07, 1.0326e-08, 6.1604e-08,\n",
            "        1.1369e-07, 4.0285e-09, 3.6599e-07, 3.0215e-08, 2.4020e-07, 3.0380e-08,\n",
            "        2.1503e-08, 1.0775e-08, 2.1315e-07, 1.7528e-07, 3.9085e-07, 2.8787e-07,\n",
            "        1.6722e-07, 1.6655e-07, 2.5720e-07, 3.0090e-07, 3.4704e-08, 1.9312e-08,\n",
            "        1.6492e-05, 1.2655e-07, 1.2368e-07, 1.2811e-07, 1.5771e-07, 7.3541e-07,\n",
            "        2.0226e-08, 1.9236e-07, 1.4837e-08, 9.6464e-08, 5.9061e-08, 4.6575e-08,\n",
            "        6.2707e-07, 3.2251e-07, 1.1005e-07, 3.0724e-07, 3.4464e-07, 5.2785e-08,\n",
            "        1.0140e-07, 2.9551e-08, 8.0340e-09, 4.6271e-08, 4.7885e-08, 9.1142e-09,\n",
            "        5.3320e-09, 4.9678e-08, 3.3653e-07, 1.4787e-07, 2.2319e-07, 5.6224e-08,\n",
            "        2.9708e-07, 1.5427e-07, 1.0018e-07, 7.8505e-08, 1.5701e-08, 1.5119e-07,\n",
            "        2.8023e-07, 3.7859e-08, 8.2486e-08, 4.6472e-08, 1.8373e-08, 8.0612e-07,\n",
            "        3.3755e-08, 1.6264e-07, 5.4198e-10, 4.0917e-08, 4.7580e-08, 6.7007e-09,\n",
            "        2.4032e-07, 4.4511e-05, 1.8761e-07, 4.9963e-08, 1.9899e-08, 9.6009e-08,\n",
            "        3.2653e-07, 1.0596e-06, 2.0500e-08, 1.7776e-07, 5.2897e-08, 2.8140e-08,\n",
            "        2.0984e-08, 1.3256e-07, 7.7333e-08, 3.0895e-08, 3.7836e-08, 1.0865e-08,\n",
            "        3.8551e-08, 2.6524e-07, 2.8871e-07, 1.8188e-07, 4.7051e-08, 4.3812e-07,\n",
            "        1.2616e-07, 1.8826e-08, 3.1523e-08, 2.4157e-07, 2.7348e-08, 2.0062e-08,\n",
            "        5.2227e-08, 2.6586e-08, 1.3453e-07, 3.5947e-07, 4.8259e-07, 5.0215e-08,\n",
            "        6.1649e-08, 2.1713e-07, 4.8608e-07, 1.1949e-07, 1.8925e-07, 2.4013e-07,\n",
            "        1.8088e-08, 4.4492e-08, 1.7319e-08, 2.7715e-08, 2.5820e-07, 3.4678e-07,\n",
            "        1.1449e-05, 1.6560e-08, 4.4061e-08, 3.9369e-08, 1.1630e-08, 1.9996e-09,\n",
            "        2.6692e-08, 8.1262e-08, 7.0776e-09, 8.8692e-07, 6.6497e-08, 1.2542e-08,\n",
            "        3.5586e-08, 2.6881e-08, 1.9871e-08, 5.6323e-08, 3.3143e-08, 9.9331e-08,\n",
            "        3.7081e-07, 3.6696e-08, 5.6270e-08, 2.9870e-08, 6.6749e-09, 3.0097e-08,\n",
            "        8.7786e-06, 1.4130e-08, 1.8020e-07, 1.6557e-07, 3.9949e-07, 2.6017e-08,\n",
            "        2.9431e-07, 3.3215e-08, 1.0733e-08, 1.1853e-07, 7.7990e-09, 1.0511e-08,\n",
            "        2.0364e-08, 8.1640e-08, 4.0493e-08, 2.0787e-08, 3.4296e-08, 8.7276e-08,\n",
            "        4.4282e-08, 1.7785e-09, 9.9849e-07, 1.4496e-06, 2.3143e-07, 7.0443e-08,\n",
            "        2.6236e-08, 9.0221e-08, 3.3691e-07, 1.8932e-08, 2.7472e-07, 1.1870e-08,\n",
            "        8.0060e-09, 9.9683e-08, 9.7432e-09, 4.3988e-08, 1.8518e-07, 1.6843e-07,\n",
            "        3.0515e-07, 6.3705e-08, 4.1760e-08, 1.6937e-07, 6.6258e-08, 2.9977e-09,\n",
            "        6.1116e-08, 1.5883e-08, 7.6940e-09, 5.5658e-08, 8.9431e-10, 4.0575e-08,\n",
            "        5.9840e-09, 6.3923e-09, 2.7594e-09, 4.3483e-09, 4.0895e-09, 3.7822e-06,\n",
            "        8.3752e-09, 9.9926e-09, 4.5091e-08, 6.1663e-10, 5.1831e-09, 1.5318e-07,\n",
            "        5.4759e-08, 1.7677e-07, 2.5643e-07, 3.3771e-07, 1.1144e-08, 1.5758e-09,\n",
            "        4.9049e-08, 5.7115e-07, 8.2850e-09, 1.7346e-09, 2.9611e-09, 2.7437e-08,\n",
            "        5.0153e-07, 1.2224e-07, 5.6019e-09, 8.8352e-09, 4.5241e-09, 2.0733e-08,\n",
            "        2.7105e-08, 4.7836e-09, 1.5041e-08, 5.0161e-08, 6.2402e-08, 6.2928e-09,\n",
            "        1.8957e-08, 1.6209e-07, 5.4797e-09, 8.9128e-09, 4.3040e-10, 7.0131e-09,\n",
            "        4.8259e-08, 9.5580e-10, 5.9642e-08, 3.1602e-08, 1.2120e-07, 3.4439e-07,\n",
            "        2.4218e-08, 2.1158e-09, 6.6399e-08, 6.8796e-07, 1.4279e-08, 1.6187e-07,\n",
            "        2.5770e-08, 3.4816e-08, 4.0268e-08, 8.5079e-08, 2.3608e-07, 1.8331e-08,\n",
            "        3.2907e-08, 1.5054e-08, 8.1400e-09, 1.5156e-07, 2.3134e-09, 1.7163e-08,\n",
            "        2.0577e-08, 6.3081e-08, 4.4850e-08, 2.4505e-10, 1.2102e-08, 3.9299e-08,\n",
            "        1.2409e-08, 4.1150e-09, 1.3263e-07, 9.3352e-07], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwZE0HZ9aLln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e8b936-96ad-4c6c-f7bc-4597fc6238fe"
      },
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-13 13:47:27--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: â€˜imagenet_classes.txtâ€™\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-13 13:47:27 (95.0 MB/s) - â€˜imagenet_classes.txtâ€™ saved [10472/10472]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9750rw9aN5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317f51be-6c2b-4708-dfe8-58ca9ae64daf"
      },
      "source": [
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "# Show top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samoyed 0.8846219182014465\n",
            "Arctic fox 0.0458051860332489\n",
            "white wolf 0.04427620768547058\n",
            "Pomeranian 0.005621347576379776\n",
            "Great Pyrenees 0.00465201074257493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "QbRglgtX86ly",
        "outputId": "98a0d281-a2f8-432a-a6d9-9c83b0481cd0"
      },
      "source": [
        "# image preprocessing\n",
        "resize_normalize = transforms.Compose([\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "# instantiate randomly initialised VGG19\n",
        "# model = R\n",
        "model.eval()\n",
        "\n",
        "# predict example frames \n",
        "for img in example_frames:\n",
        "  \n",
        "    input_img = V(resize_normalize(img).unsqueeze(0))\n",
        "    activations = model(input_img)\n",
        "\n",
        "print_ResNet_Predictions(activations[-1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c9e50d7d5dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# predict example frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'example_frames' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXeCKfW06nTp"
      },
      "source": [
        "#exporting model to cuda\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHGs7ZYlWRsr"
      },
      "source": [
        "# **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ioq42NXWXJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bdde1d4-9bd5-432d-fe5b-fd8fd35ca56a"
      },
      "source": [
        "# download dataset from dropbox\n",
        "dropbox_link = 'https://www.dropbox.com/s/agxyxntrbwko7t1/participants_data.zip?dl=0'\n",
        "os.environ['download_link'] = dropbox_link \n",
        "!echo $download_link\n",
        "!wget -O participants_data.zip -c $download_link\n",
        "!wget -c https://raw.githubusercontent.com/Neural-Dynamics-of-Visual-Cognition-FUB/Algonauts2021_devkit/main/class_names_ImageNet.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.dropbox.com/s/agxyxntrbwko7t1/participants_data.zip?dl=0\n",
            "--2021-08-13 13:47:52--  https://www.dropbox.com/s/agxyxntrbwko7t1/participants_data.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/agxyxntrbwko7t1/participants_data.zip [following]\n",
            "--2021-08-13 13:47:52--  https://www.dropbox.com/s/raw/agxyxntrbwko7t1/participants_data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com/cd/0/inline/BUJ-T-WZs1Ghn8VuGMRzK0UXrMY-kMiOjqG4zNUEG5ugQZ_3CCagk3FXqd0JQnV40af6YYDkn6VgjixgKdEvIaByZAzYhFdnvFZrKEan6lrLX5ZbJftQufeHTJh_IANAZr0i95nBIyUVtEngzZ5L2_28/file# [following]\n",
            "--2021-08-13 13:47:52--  https://uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com/cd/0/inline/BUJ-T-WZs1Ghn8VuGMRzK0UXrMY-kMiOjqG4zNUEG5ugQZ_3CCagk3FXqd0JQnV40af6YYDkn6VgjixgKdEvIaByZAzYhFdnvFZrKEan6lrLX5ZbJftQufeHTJh_IANAZr0i95nBIyUVtEngzZ5L2_28/file\n",
            "Resolving uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com (uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com (uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BUI-RKtXTyZZWkhNROLFZZ00FURfz3XyfQV_7QhTp5zbcK_QwpccKVJpuQYjm5RwsM9pQ7hmZFgW6JRZUTYjfKxcv5oImAZdhptkuMjpaOmISf4POwqMHEzM1AnMPYcYp2BEgyvU1R9WeGhkNkOzSw1EdsVLDqMgNQfdhGTMDVRcvj9NsFdHnDdV4ApiVuRg2r9HHuaabxGj_7dd2Fgsyj9NVgsloXNw1h88YGDfEG7Lz4zZL5xs_Nc-2cSHmrcu95zQCVHHHvy2bGmrvV3BgtDI4tFT5MXlnYVAozlyWi97ckTUN3Ros-2qG3Gw7HtG-ome6oWdHOBPh69I0MnQNlldEi5Z73gUcqyuQK9zlxio1qt4EhEhMTHPOxrK-FPMM-8/file [following]\n",
            "--2021-08-13 13:47:52--  https://uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com/cd/0/inline2/BUI-RKtXTyZZWkhNROLFZZ00FURfz3XyfQV_7QhTp5zbcK_QwpccKVJpuQYjm5RwsM9pQ7hmZFgW6JRZUTYjfKxcv5oImAZdhptkuMjpaOmISf4POwqMHEzM1AnMPYcYp2BEgyvU1R9WeGhkNkOzSw1EdsVLDqMgNQfdhGTMDVRcvj9NsFdHnDdV4ApiVuRg2r9HHuaabxGj_7dd2Fgsyj9NVgsloXNw1h88YGDfEG7Lz4zZL5xs_Nc-2cSHmrcu95zQCVHHHvy2bGmrvV3BgtDI4tFT5MXlnYVAozlyWi97ckTUN3Ros-2qG3Gw7HtG-ome6oWdHOBPh69I0MnQNlldEi5Z73gUcqyuQK9zlxio1qt4EhEhMTHPOxrK-FPMM-8/file\n",
            "Reusing existing connection to uc3190fa121ea7655a1ae610c23a.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4591675883 (4.3G) [application/zip]\n",
            "Saving to: â€˜participants_data.zipâ€™\n",
            "\n",
            "participants_data.z 100%[===================>]   4.28G  35.4MB/s    in 84s     \n",
            "\n",
            "2021-08-13 13:49:17 (51.9 MB/s) - â€˜participants_data.zipâ€™ saved [4591675883/4591675883]\n",
            "\n",
            "--2021-08-13 13:49:21--  https://raw.githubusercontent.com/Neural-Dynamics-of-Visual-Cognition-FUB/Algonauts2021_devkit/main/class_names_ImageNet.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21674 (21K) [text/plain]\n",
            "Saving to: â€˜class_names_ImageNet.txtâ€™\n",
            "\n",
            "class_names_ImageNe 100%[===================>]  21.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-13 13:49:22 (86.8 MB/s) - â€˜class_names_ImageNet.txtâ€™ saved [21674/21674]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRGzEbE2Wfs2"
      },
      "source": [
        "# unzip data file (%%capture suppresses the output)\n",
        "%%capture\n",
        "!unzip -o participants_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_BbXlZkWlGj"
      },
      "source": [
        "# **Video Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdtzEKUYWp9T",
        "outputId": "d439c057-8844-4a15-b890-54ce03f06a36"
      },
      "source": [
        "# Colab directory containing videos\n",
        "video_dir = '/content/AlgonautsVideos268_All_30fpsmax'\n",
        "\n",
        "# get path of all videos\n",
        "video_list = glob.glob(video_dir + '/*.mp4')\n",
        "\n",
        "# sort videos in ascending order\n",
        "video_list.sort()\n",
        "\n",
        "print('Total number of videos: ', len(video_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of videos:  1102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbok1SNXWvZN"
      },
      "source": [
        "def sample_video_from_mp4(file, num_frames = 16):\n",
        "    \"\"\"This function takes a mp4 video file as input and returns\n",
        "    an array of uniformly sampled frames.\n",
        "    \n",
        "    Args\n",
        "    ----------\n",
        "    file : str\n",
        "        path to mp4 video file\n",
        "    num_frames : int\n",
        "        number of frames to select with uniform frame sampling\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    frames: list of frames as PIL images\n",
        "    num_frames: number of sampled frames\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # read video file\n",
        "    video = VideoReader(file)\n",
        "\n",
        "    # get total number of video frames\n",
        "    total_frames = len(video)\n",
        "\n",
        "    # create frame indices \n",
        "    frame_indices = np.linspace(0, total_frames-1, num_frames, dtype = np.int) \n",
        "\n",
        "    video_frames = []\n",
        "\n",
        "    # fill list of video frames as PIL images\n",
        "    for i in frame_indices:\n",
        "      video_frames.append(Image.fromarray(video[i].asnumpy()))\n",
        "\n",
        "    return video_frames, num_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_ODuC8gWyNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40702d95-a24d-4f80-c359-234335aba9da"
      },
      "source": [
        "# example of using the previous function\n",
        "example_frames, num_frames = sample_video_from_mp4(video_list[8])\n",
        "len(example_frames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "OIznb2aN8kgy",
        "outputId": "f0f7e1d4-db75-4fd5-dc3f-ad4a09352318"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "inputs_bat, labels = inputs.to(device), labels.to(device)\n",
        "# inputs, labels = inputs.cuda(), labels.cuda() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6834e79c9e26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs_bat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# inputs, labels = inputs.cuda(), labels.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--r8qDHvATyd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTmjjuzqwDTo"
      },
      "source": [
        "# **Activate**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-BB6U8xwJth"
      },
      "source": [
        "def get_activations_and_save(model, video_list, save_dir, layer):\n",
        "    \"\"\"This function extracts the activations (features) of a specific layer of\n",
        "    a model to a set of videos and save them in a specified directory. Every\n",
        "    file is a list with a vector containing the activations of that layer to\n",
        "    a particular video. The activations are averaged over the frames of every\n",
        "    video. \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model :\n",
        "        pytorch model.\n",
        "    video_list : list\n",
        "        list containing path to all videos.\n",
        "    save_dir : str\n",
        "        save path for extracted activations.\n",
        "    layer : int\n",
        "        integer specifying layer number.\n",
        "    \"\"\"\n",
        "    \n",
        "    # define preprocessing function\n",
        "    preprocess = transforms.Compose([\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    for video in video_list:\n",
        "      \n",
        "      # name video file\n",
        "      video_file_name = os.path.split(video)[-1].split(\".\")[0]\n",
        "      \n",
        "      # load video frames\n",
        "      video_frames, num_frames = sample_video_from_mp4(video)\n",
        "      \n",
        "      activations = []\n",
        "      for frame, image in enumerate(video_frames):\n",
        "        \n",
        "        # preprocess video frame\n",
        "        input_image = V(resize_normalize(image).unsqueeze(0))\n",
        "\n",
        "        # feed image through the model  #### check predict\n",
        "        layer_outputs = model.forward(input_image)\n",
        "\n",
        "        if frame==0:\n",
        "          # append and flatten layer activations\n",
        "          activations.append(layer_outputs[layer].ravel())\n",
        "        else:\n",
        "          # add activations over frames\n",
        "          activations =  activations + layer_outputs[layer].ravel()\n",
        "        \n",
        "        # average layer activations across frames\n",
        "        avg_layer_activations = np.array([activations])/float(num_frames)\n",
        "        \n",
        "        # define saving directory\n",
        "        save_path = os.path.join(save_dir, video_file_name + \"_\" +\n",
        "                               \"layer\" + \"_\" + str(layer) + \".npy\")\n",
        "\n",
        "        # save activations for a particular video\n",
        "        np.save(save_path, avg_layer_activations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "9Pkn3M27wUwx",
        "outputId": "cf27afda-a6df-4aad-f037-9ca9120d7f20"
      },
      "source": [
        "############################### change dir ###########################\n",
        "# create saving directory for activations\n",
        "activations_dir = \"/content/activations_ResNet\"\n",
        "if not os.path.exists(activations_dir):\n",
        "  os.makedirs(activations_dir)\n",
        "\n",
        "# get activations\n",
        "get_activations_and_save(model, video_list[:30], activations_dir, layer = 1)   ##### SPECIFY LAYER NUMBER #####"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b36982e71792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# get activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mget_activations_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m##### SPECIFY LAYER NUMBER #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-35b2222136be>\u001b[0m in \u001b[0;36mget_activations_and_save\u001b[0;34m(model, video_list, save_dir, layer)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# feed image through the model  #### check predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju14sxUryttG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}